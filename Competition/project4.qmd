---
title: "Client Report - Can You Predict That?"
subtitle: "Course DS 250"
author: "Francis Senessie"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false 
---

```{python}
import pandas as pd 
import numpy as np
from lets_plot import *
# add the additional libraries you need to import for ML here

LetsPlot.setup_html(isolated_frame=True)
```

```{python}
# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html

# Include and execute your code here

# import your data here using pandas and the URL

df = pd.read_csv("https://github.com/byuidatascience/data4dwellings/raw/master/data-raw/dwellings_ml/dwellings_ml.csv")
df
```

## Elevator pitch
_A SHORT (2-3 SENTENCES) PARAGRAPH THAT `DESCRIBES KEY INSIGHTS` TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS._ 
(Note: this is not a summary of the project, but a summary of the results.)

_A Client has requested this analysis and this is your one shot of what you would say to your boss in a 2 min elevator ride before he takes your report and hands it to the client._

## QUESTION|TASK 1

__Create 2-3 charts that evaluate potential relationships between the home variables and `before1980`.__ 


Explain what you learn from the charts that could help a machine learning algorithm. 

_The box plots compare livearea (total living area) and finbsmnt (finished basement area) between homes built before and after 1980. Homes built after 1980 generally have larger median living areas and finished basements, with greater variability in size. The presence of outliers, particularly in newer homes, suggests a wider range of home sizes over time. These differences indicate that before1980 could be an important categorical feature in a machine learning model, as it correlates with home size and layout trends, potentially impacting predictions related to home value or characteristics._

```{python}
LetsPlot.setup_html()
box_plot = ggplot(df, aes (x='before1980', y='livearea')) + \
  geom_boxplot () +\
coord_cartesian (ylim=(0, 5000))
box_plot.show()
df
```

```{python}
LetsPlot.setup_html()
box_plot = ggplot(df, aes(x='before1980', y='finbsmnt')) + \
  geom_boxplot () + \
  coord_cartesian (ylim=(0, 5000))

box_plot.show()
```

## QUESTION|TASK 2

__Build a classification model labeling houses as being built “before 1980” or “during or after 1980”.__ Your goal is to reach or exceed 90% accuracy. Explain your final model choice (algorithm, tuning parameters, etc) and describe what other models you tried.  

_The code builds a Random Forest classification model to predict whether a home was built before 1980 using various home features. First, it preprocesses the dataset by dropping non-relevant columns (parcel and year built), encoding categorical variables with one-hot encoding, and splitting the data into training and testing sets. The model is trained using 100 decision trees (n_estimators=100) and evaluated on the test set. The accuracy score is printed along with a classification report, showing performance metrics like precision, recall, and F1-score. Additionally, the feature importance values from the Random Forest model are displayed, helping to identify which variables contribute the most to the prediction. The goal is to achieve at least 90% accuracy in classifying homes based on their construction period._

```{python}
# Include and execute your code here
# 1. Random Forest Classifier:
from sklearn.model_selection import train_test_split 
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn import metrics 
import pandas as pd

# Separate features and target variable
X = df.drop(columns= ['before1980','parcel', 'yrbuilt'])
y = df['before1980']

# Identify categorical columns
categorical_columns = X.select_dtypes (include=['object']).columns
# Apply pd. get_dummies to the categorical columns
X_dummies = pd.get_dummies(X, columns=categorical_columns, drop_first=True)
# Train-test split using the transformed data (_dummies)
X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=42)
# Initialize the RandomForestClassifier
clf = RandomForestClassifier(n_estimators=100, random_state=42)
# Train the model
clf. fit(X_train, y_train)
# Predict and evaluate
y_pred = clf. predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print (f"Accuracy: (accuracy * 100:.2f)%")
print (metrics.classification_report(y_test, y_pred))
# Feature importance analysis (from Random Forest model)
importances = clf. feature_importances_
print ("Feature importances:",importances)
```


## QUESTION|TASK 3

__Justify your classification model by discussing the most important features selected by your model.__ 
This discussion should include a feature importance chart and a description of the features. 

_The code evaluates the feature importance in the Random Forest classification model used to predict whether a home was built before 1980. After preprocessing the dataset by encoding categorical variables and removing unnecessary columns, the model is trained and evaluated, achieving an accuracy score. The feature importance values are then extracted and visualized using a bar plot, where the most influential features are displayed. This helps identify key factors contributing to the prediction, such as home size, basement area, or specific categorical attributes. The flipped bar chart makes it easier to interpret which features have the highest impact, aiding in refining the model and understanding the underlying data patterns._

```{python}
# Include and execute your code here
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from lets_plot import *

# Drop unnecessary columns
columns_to_drop = ['before1980', 'parcel', 'yrbuilt']
df_cleaned = df.drop(columns=[col for col in columns_to_drop if col in df.columns])

# Separate features and target variable
X = df_cleaned
y = df['before1980']  # Removed the extra space in column name

# Identify categorical columns
categorical_columns = X.select_dtypes(include=['object']).columns

# Apply pd.get_dummies to categorical columns
X_dummies = pd.get_dummies(X, columns=categorical_columns, drop_first=True)

# Avoid multicollinearity
X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=42)

# Train the model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predict on test set
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

# Feature importance analysis (Final Fix)
feature_importances = pd.DataFrame({
    'Feature': list(X_dummies.columns),  # Ensure it's a list
    'Importance': model.feature_importances_  # Ensure it's the correct attribute
})

# Sort values correctly
feature_importances = feature_importances.sort_values(by='Importance', ascending=True)

# Initialize lets-plot
LetsPlot.setup_html()

# Create a ggplot-style bar plot for feature importance
plot = ggplot(feature_importances) + \
    geom_bar(aes(x='Feature', y='Importance'), stat='identity', fill='blue') + \
    ggtitle('Feature Importance in Random Forest Classifier (Using Dummies)') + \
    xlab('Feature') + \
    ylab('Feature Importance') + \
    coord_flip()  # Flip axes for better readability

# Display the plot
plot
```

## QUESTION|TASK 4

__Describe the quality of your classification model using 2-3 different evaluation metrics.__ You also need to explain how to interpret each of the evaluation metrics you use.  

_Model Evaluation and Interpretation
The classification model was evaluated using Accuracy, Precision, Recall, and F1-Score, along with a Confusion Matrix. The classification report provides key evaluation metrics that help assess the model's predictive ability, indicating whether it favors one class over the other and identifying areas for improvement.

Accuracy (93%): Accuracy measures the proportion of correctly classified instances out of all predictions. The model achieved high accuracy, correctly classifying most homes in the dataset.

Precision (0.91 for class 0, 0.94 for class 1): Precision evaluates how many homes predicted as a certain class were correctly classified. A precision of 0.91 for homes built after 1980 and 0.94 for homes built before 1980 indicates a low false positive rate, meaning the model makes confident and correct predictions.

Recall (0.90 for class 0, 0.95 for class 1): Recall measures how well the model captures actual instances of each class. The high recall values suggest the model effectively identifies most homes in each category, with a slight tendency to predict homes built before 1980 more accurately.

F1-Score (0.93 macro average): The F1-score balances precision and recall, providing a single performance metric. The high F1-score confirms that the model effectively distinguishes between homes built before and after 1980.

The support column in the classification report shows the number of actual instances for each class in the test set, which helps in understanding class distribution. The confusion matrix reveals that the model performs well in classifying both categories, with very few misclassifications. Compared to a previous model with 48% accuracy, this improved model demonstrates significant enhancements in predictive ability, suggesting the effectiveness of better feature selection, hyperparameter tuning, and data preprocessing.

Recommendations for Further Improvement:
Feature Engineering: Exploring additional home attributes (e.g., year of last renovation, neighborhood characteristics) may further refine predictions.
Hyperparameter Tuning: Adjusting parameters such as tree depth and the number of estimators could provide additional accuracy gains.
Cross-Validation: Implementing k-fold cross-validation could ensure the model generalizes well across different data splits.
With 93% accuracy and strong classification performance, this model is well-suited for predicting whether a home was built before or after 1980._

```{python}
# Include and execute your code here
print (metrics.classification_report(y_test, y_pred))
print ("Feature importances:",importances)
```
